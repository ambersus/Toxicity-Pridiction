{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f200698-289a-4987-8189-78ad6f47eb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    7408\n",
      "1     423\n",
      "Name: count, dtype: int64\n",
      "------------------\n",
      "label\n",
      "0    7408\n",
      "1     423\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "858ed4bb-b3ea-4f12-8268-ea2dce33e511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    7408\n",
      "1     423\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    7408\n",
      "1    7408\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e733785-2c25-4b56-a092-ebe930341639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    7408\n",
      "1     423\n",
      "Name: count, dtype: int64\n",
      "------------------\n",
      "label\n",
      "0    7408\n",
      "1     423\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    7408\n",
      "1    7408\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:29:41] Explicit valence for atom # 5 Al, 6, is greater than permitted\n",
      "[20:29:43] Explicit valence for atom # 3 Al, 6, is greater than permitted\n",
      "[20:29:43] Explicit valence for atom # 4 Al, 6, is greater than permitted\n",
      "[20:29:43] Explicit valence for atom # 9 Al, 6, is greater than permitted\n",
      "[20:29:45] Explicit valence for atom # 4 Al, 6, is greater than permitted\n",
      "[20:29:45] Explicit valence for atom # 14 Al, 6, is greater than permitted\n",
      "[20:29:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[20:29:49] Explicit valence for atom # 8 Al, 6, is greater than permitted\n",
      "[20:29:51] Explicit valence for atom # 20 Al, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: SVM\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       0.72      0.71      0.71      1476\n",
      "       Toxic       0.71      0.72      0.72      1486\n",
      "\n",
      "    accuracy                           0.71      2962\n",
      "   macro avg       0.71      0.71      0.71      2962\n",
      "weighted avg       0.71      0.71      0.71      2962\n",
      "\n",
      "Accuracy: 0.71\n",
      "ROC-AUC Score: 0.78\n",
      "\n",
      "Model: KNN\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       0.91      0.65      0.76      1476\n",
      "       Toxic       0.73      0.94      0.82      1486\n",
      "\n",
      "    accuracy                           0.80      2962\n",
      "   macro avg       0.82      0.80      0.79      2962\n",
      "weighted avg       0.82      0.80      0.79      2962\n",
      "\n",
      "Accuracy: 0.80\n",
      "ROC-AUC Score: 0.89\n",
      "\n",
      "Model: RandomForest\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       1.00      0.92      0.96      1476\n",
      "       Toxic       0.92      1.00      0.96      1486\n",
      "\n",
      "    accuracy                           0.96      2962\n",
      "   macro avg       0.96      0.96      0.96      2962\n",
      "weighted avg       0.96      0.96      0.96      2962\n",
      "\n",
      "Accuracy: 0.96\n",
      "ROC-AUC Score: 0.96\n",
      "\n",
      "Model: Self-Organizing Neural Network (SNN)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       0.71      0.65      0.68      1476\n",
      "       Toxic       0.68      0.74      0.71      1486\n",
      "\n",
      "    accuracy                           0.69      2962\n",
      "   macro avg       0.70      0.69      0.69      2962\n",
      "weighted avg       0.70      0.69      0.69      2962\n",
      "\n",
      "Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "from minisom import MiniSom\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\Sushma\\Desktop\\Acadamics\\4th sem\\BIO-2\\project\\tox21.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "print(data['label'].value_counts())\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates(subset='smiles').reset_index(drop=True)\n",
    "\n",
    "# Optional: Reset index\n",
    "data = data.reset_index(drop=True)\n",
    "print(\"------------------\")\n",
    "print(data['label'].value_counts())\n",
    "from sklearn.utils import resample\n",
    "\n",
    "majority = data[data.label == 0]\n",
    "minority = data[data.label == 1]\n",
    "\n",
    "minority_oversampled = resample(minority, \n",
    "                                replace=True, \n",
    "                                n_samples=len(majority), \n",
    "                                random_state=42)\n",
    "\n",
    "data_balanced = pd.concat([majority, minority_oversampled]).reset_index(drop=True)\n",
    "print(data_balanced['label'].value_counts())\n",
    "\n",
    "\n",
    "# Preprocessing SMILES strings to molecular descriptors\n",
    "def calculate_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        return {\n",
    "            \"MolecularWeight\": Descriptors.MolWt(mol),\n",
    "            \"NumAtoms\": Descriptors.HeavyAtomCount(mol),\n",
    "            \"NumRotatableBonds\": Descriptors.NumRotatableBonds(mol),\n",
    "            \"LogP\": Descriptors.MolLogP(mol),\n",
    "        }\n",
    "    else:\n",
    "        return {\"MolecularWeight\": np.nan, \"NumAtoms\": np.nan, \"NumRotatableBonds\": np.nan, \"LogP\": np.nan}\n",
    "\n",
    "# Apply descriptor calculation\n",
    "descriptors = data_balanced[\"smiles\"].apply(calculate_descriptors)\n",
    "descriptors_df = pd.DataFrame(descriptors.tolist())\n",
    "\n",
    "# Combine descriptors with labels and remove NaNs\n",
    "data_balanced = pd.concat([descriptors_df, data_balanced[\"label\"]], axis=1).dropna()\n",
    "\n",
    "# Split dataset into features and target\n",
    "X = data_balanced.drop(\"label\", axis=1)\n",
    "y = data_balanced[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"SVM\": SVC(kernel=\"rbf\", probability=True),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=20),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=1, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate traditional models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"\\nModel: {name}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Non-Toxic\", \"Toxic\"]))\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "    if y_proba is not None:\n",
    "        print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_proba):.2f}\")\n",
    "\n",
    "# Self-Organizing Neural Network (SNN) using MiniSom\n",
    "print(\"\\nModel: Self-Organizing Neural Network (SNN)\")\n",
    "\n",
    "# Define and train the SOM\n",
    "som = MiniSom(x=10, y=10, input_len=X_train.shape[1], sigma=1.0, learning_rate=0.7, random_seed=42)\n",
    "som.train_random(X_train, num_iteration=1000)\n",
    "\n",
    "# Function to extract SOM features\n",
    "def get_som_features(som, data):\n",
    "    som_x, som_y = som._weights.shape[:2]  # Get SOM grid dimensions\n",
    "    feature_vector = np.zeros((data.shape[0], som_x * som_y))\n",
    "    \n",
    "    for i, sample in enumerate(data):\n",
    "        x, y = som.winner(sample)  # Get SOM cluster coordinates\n",
    "        feature_vector[i, x * som_y + y] = 1  # One-hot encode cluster\n",
    "    \n",
    "    return feature_vector\n",
    "\n",
    "# Transform train and test sets into SOM feature space\n",
    "X_train_som = get_som_features(som, X_train)\n",
    "X_test_som = get_som_features(som, X_test)\n",
    "\n",
    "# Train a classifier on the extracted features\n",
    "rf_on_snn = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_on_snn.fit(X_train_som, y_train)\n",
    "\n",
    "# Evaluate SNN-based model\n",
    "y_pred_snn = rf_on_snn.predict(X_test_som)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_snn, target_names=[\"Non-Toxic\", \"Toxic\"]))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_snn):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76d77492-33f6-405c-9a8e-053fb523cc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MolecularWeight     NumAtoms  NumRotatableBonds         LogP  \\\n",
      "count      7823.000000  7823.000000        7823.000000  7823.000000   \n",
      "mean        276.144155    18.566918           4.302953     2.373943   \n",
      "std         164.732356    11.309542           4.464812     2.304307   \n",
      "min           9.012000     1.000000           0.000000   -17.406400   \n",
      "25%         165.236000    11.000000           1.000000     1.149350   \n",
      "50%         240.302000    16.000000           3.000000     2.365500   \n",
      "75%         343.044000    23.000000           6.000000     3.653150   \n",
      "max        1877.664000   132.000000          47.000000    22.611800   \n",
      "\n",
      "             label  \n",
      "count  7823.000000  \n",
      "mean      0.054071  \n",
      "std       0.226173  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       0.000000  \n",
      "75%       0.000000  \n",
      "max       1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d3b58c1-7472-4271-8fc9-00e9f8a71bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.9723\n",
      "Ensemble Model F1 Score: 0.9725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97      1516\n",
      "           1       0.95      1.00      0.97      1448\n",
      "\n",
      "    accuracy                           0.97      2964\n",
      "   macro avg       0.97      0.97      0.97      2964\n",
      "weighted avg       0.97      0.97      0.97      2964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv( r\"C:\\Users\\Sushma\\Desktop\\Acadamics\\4th sem\\BIO-2\\project\\tox21.csv\")\n",
    "\n",
    "# Drop duplicates and NaNs if necessary\n",
    "data = data.drop_duplicates(subset=\"smiles\").dropna(subset=[\"smiles\", \"label\"]).reset_index(drop=True)\n",
    "\n",
    "# Balance the dataset using oversampling\n",
    "majority = data[data['label'] == 0]\n",
    "minority = data[data['label'] == 1]\n",
    "\n",
    "minority_oversampled = resample(minority, \n",
    "                                replace=True, \n",
    "                                n_samples=len(majority), \n",
    "                                random_state=42)\n",
    "\n",
    "data_balanced = pd.concat([majority, minority_oversampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Encode SMILES strings to fixed-length numeric arrays\n",
    "def smiles_to_placeholder(smiles_list, max_length=100):\n",
    "    encoded = []\n",
    "    for smiles in smiles_list:\n",
    "        numeric = [ord(char) for char in smiles[:max_length]]\n",
    "        padded = numeric + [0] * (max_length - len(numeric)) if len(numeric) < max_length else numeric\n",
    "        encoded.append(padded)\n",
    "    return np.array(encoded)\n",
    "\n",
    "# Encode and prepare features and labels\n",
    "X = smiles_to_placeholder(data_balanced['smiles'])\n",
    "y = data_balanced['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize individual models\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "svm = SVC(probability=True)\n",
    "\n",
    "# Fit individual models\n",
    "rf.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Create and train ensemble VotingClassifier\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('rf', rf),\n",
    "    ('knn', knn),\n",
    "    ('svm', svm)\n",
    "], voting='soft', weights=[0.5, 0.3, 0.3])\n",
    "\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "final_preds = ensemble_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, final_preds)\n",
    "f1 = f1_score(y_test, final_preds)\n",
    "\n",
    "print(f\"Ensemble Model Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Ensemble Model F1 Score: {f1:.4f}\")\n",
    "print(classification_report(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5465ed9-8086-4b0a-afba-48f538b2bcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
